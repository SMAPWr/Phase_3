{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Detector - EN - Features extraction for SVM & Dense model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [this notebook](https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/classifier/final_classifier.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "from klepto.archives import dir_archive\n",
    "import sys\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import fasttext\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "import syllables as sylla\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'dense'\n",
    "dim = 10 if MODEL == 'svm' else 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davidson et al. data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes pre:\n",
    "    0 - hate speech\n",
    "    1 - offensive language\n",
    "    2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('hsd/DavidsonEtAl/perfect_data.pkl'):\n",
    "    tweets, labels = [], []\n",
    "    with open('hsd/DavidsonEtAl/labeled_data.csv', 'r') as f:\n",
    "        for d in tqdm(list(csv.reader(f))[1:]):\n",
    "            tweets.append(d[6])  # tweet\n",
    "            labels.append(d[5])  # class\n",
    "    with open('hsd/DavidsonEtAl/perfect_data.pkl', 'w') as f:\n",
    "        def chcl(c):\n",
    "            return 0 if c=='2' else 1\n",
    "        labels = list(map(chcl, labels))\n",
    "        pickle.dump((tweets, labels), f)\n",
    "else:\n",
    "    with open('hsd/DavidsonEtAl/perfect_data.pkl', 'rb') as f:\n",
    "        tweets, labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes post:\n",
    "    0 - no hate\n",
    "    1 - hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets: 24783\n",
      "Labels: 24783\n"
     ]
    }
   ],
   "source": [
    "print('Tweets: {}'.format(len(tweets)))\n",
    "print('Labels: {}'.format(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\",\n",
       "  0),\n",
       " ('!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!',\n",
       "  1),\n",
       " ('!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit',\n",
       "  1),\n",
       " ('!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny', 1),\n",
       " ('!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;',\n",
       "  1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(tweets[:5], labels[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = VS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    #hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    #parsed_text = re.sub(hashtag_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "def get_pos_string(tweet):\n",
    "    text = preprocess(tweet)\n",
    "    tokens = basic_tokenize(preprocess(text))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = ' '.join(tag_list)\n",
    "    \n",
    "    return tag_str\n",
    "\n",
    "def pad_words(words, length):\n",
    "    if len(words) >= length:\n",
    "        return words[:length]\n",
    "    else:\n",
    "        additional = length - len(words)\n",
    "        return words + ['EMPTY']*additional\n",
    "\n",
    "def adjust_words(words, length):\n",
    "    # different from pad: output tokens may contain more than 1 words\n",
    "    if len(words) >= length:\n",
    "        q, r = divmod(len(words), length)\n",
    "        return [' '.join(words[i * q + min(i, r):(i + 1) * q + min(i + 1, r)]) for i in xrange(length)]\n",
    "    else:\n",
    "        additional = length - len(words)\n",
    "        return words + ['EMPTY']*additional\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised fastText wordtokens training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('hsd/DavidsonEtAl/fasttext.ft'):\n",
    "    with open('hsd/DavidsonEtAl/fasttext.ft', 'a') as f:\n",
    "        for t, l in list(zip(tweets, labels)):\n",
    "            f.write('__label__{} {}\\n'.format(l, preprocess(t)))\n",
    "\n",
    "# load fasttext model or train & save if none\n",
    "if os.path.exists('hsd/DavidsonEtAl/fasttext_{}.bin'.format(MODEL)):\n",
    "    ft_model = fasttext.load_model('hsd/DavidsonEtAl/fasttext_{}.bin'.format(MODEL))\n",
    "else:\n",
    "    ft_model = fasttext.train_supervised('hsd/DavidsonEtAl/fasttext.ft',\n",
    "                                         lr=0.5, epoch=50, wordNgrams=3, dim=dim)\n",
    "    ft_model.save_model('hsd/DavidsonEtAl/fasttext_{}.bin'.format(MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordtoken features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordtoken_fts(data, length=None):\n",
    "    \n",
    "    sentences_words = []\n",
    "    t = tqdm(data)\n",
    "    t.set_postfix_str('Wordtokens features extraction: tokenization.')\n",
    "    for d in t:\n",
    "        sentence = preprocess(d)\n",
    "        sentences_words.append(sentence.split(' '))\n",
    "    \n",
    "    if length:\n",
    "        sentences_words = [adjust_words(sw, length) for sw in sentences_words]\n",
    "        print('Required length: {}'.format(length))\n",
    "    else:\n",
    "        opt_length = int(np.median([len(sw) for sw in sentences_words]))\n",
    "        print('Optimal median length: {}'.format(opt_length))\n",
    "        sentences_words = [pad_words(sw, opt_length) for sw in sentences_words]\n",
    "    \n",
    "    ft_vectors = []\n",
    "    t = tqdm(sentences_words)\n",
    "    t.set_postfix_str('Wordtokens features extraction: vectorization.')\n",
    "    for sw in t:\n",
    "        ft_vector = []\n",
    "        for w in sw:\n",
    "            ft_vector.extend(ft_model[w])\n",
    "        ft_vectors.append(ft_vector)\n",
    "    \n",
    "    return ft_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7afdf6732a418cafbd523bf67d12fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24783), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal median length: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461ed05e07624f3b9e9c1432df72f72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24783), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wordtoken_features = get_wordtoken_fts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005668369,\n",
       " -0.00034747657,\n",
       " -0.001978379,\n",
       " -0.010782028,\n",
       " -0.008164815,\n",
       " -0.0011637644,\n",
       " -0.0009088973,\n",
       " 0.00771439,\n",
       " -0.016118625,\n",
       " -0.013548581,\n",
       " -9.6401054e-05,\n",
       " -0.0011458383,\n",
       " -0.009378296,\n",
       " -0.0052023875,\n",
       " 0.008828382,\n",
       " 0.0026898596,\n",
       " 0.0052590333,\n",
       " 0.0018688404,\n",
       " -0.0060257055,\n",
       " 0.0012578431,\n",
       " 0.0016082253,\n",
       " -0.010305873,\n",
       " 0.0017048806,\n",
       " 0.014387419,\n",
       " -0.005722594,\n",
       " 0.0038224978,\n",
       " -0.0031750866,\n",
       " 0.010164745,\n",
       " -0.0013058862,\n",
       " -0.010249467,\n",
       " -0.003709575,\n",
       " 0.004889313,\n",
       " 0.0007671442,\n",
       " 0.0069282684,\n",
       " 0.018503733,\n",
       " -0.0053017675,\n",
       " -0.01070363,\n",
       " 0.009404537,\n",
       " -0.012469085,\n",
       " -8.573926e-05,\n",
       " -0.005705793,\n",
       " 0.0012051072,\n",
       " -0.012193572,\n",
       " -0.002764483,\n",
       " -0.0028475428,\n",
       " 0.011689077,\n",
       " -0.004050846,\n",
       " 0.005839261,\n",
       " 0.0011497809,\n",
       " -0.003882383,\n",
       " 0.0056926305,\n",
       " -0.0005382496,\n",
       " 0.012663222,\n",
       " -0.0029371234,\n",
       " 0.013023276,\n",
       " 0.009308624,\n",
       " -0.00048667996,\n",
       " 0.0044254926,\n",
       " -0.0026901201,\n",
       " -0.009312597,\n",
       " -0.0042139157,\n",
       " -0.0029657744,\n",
       " -0.0127325645,\n",
       " -0.011249677,\n",
       " -0.002320121,\n",
       " 0.0055583655,\n",
       " 0.00444989,\n",
       " -0.00081541395,\n",
       " -0.0098153325,\n",
       " -0.003265339,\n",
       " -0.00013104297,\n",
       " -0.007665968,\n",
       " 0.00036332154,\n",
       " -0.002754632,\n",
       " 0.010117771,\n",
       " -0.0053411354,\n",
       " -0.017743021,\n",
       " 0.0048134793,\n",
       " -0.0020193285,\n",
       " 0.0045666313,\n",
       " -0.005366542,\n",
       " -0.0053041587,\n",
       " -0.011159527,\n",
       " 0.015977086,\n",
       " 0.0043147677,\n",
       " -0.0036594486,\n",
       " -0.005584258,\n",
       " 0.0006326524,\n",
       " 0.003251674,\n",
       " 0.0052372394,\n",
       " -0.009192249,\n",
       " 0.00058527145,\n",
       " -0.01236775,\n",
       " 0.013020954,\n",
       " 0.0036677099,\n",
       " 0.009244844,\n",
       " -0.0022132024,\n",
       " -0.009276583,\n",
       " 0.0061676255,\n",
       " -0.0025101656,\n",
       " -0.0035284515,\n",
       " -0.01057167,\n",
       " 0.0024297482,\n",
       " 0.0005616607,\n",
       " -0.0027363435,\n",
       " -0.004459229,\n",
       " 0.004558205,\n",
       " -0.0014060934,\n",
       " -0.002988807,\n",
       " 0.00922165,\n",
       " -0.0045416555,\n",
       " -0.006620706,\n",
       " -0.004708652,\n",
       " 0.011180589,\n",
       " 0.001313246,\n",
       " 0.0063664243,\n",
       " 0.004981833,\n",
       " -0.0042055557,\n",
       " 0.00428174,\n",
       " -0.0020964255,\n",
       " 0.008887955,\n",
       " -0.005444425,\n",
       " -0.0013784792,\n",
       " -0.0071035963,\n",
       " 0.0039238064,\n",
       " 0.009344764,\n",
       " 0.006048696,\n",
       " -0.007856654,\n",
       " 0.0073559256,\n",
       " 0.0032477377,\n",
       " 0.00050487864,\n",
       " -0.004953406,\n",
       " -0.0084654195,\n",
       " 0.0031318062,\n",
       " 0.010115306,\n",
       " 0.004033553,\n",
       " 0.0018044626,\n",
       " 0.007384434,\n",
       " 0.0014433861,\n",
       " 0.0055191624,\n",
       " 0.006625234,\n",
       " -0.0029979355,\n",
       " 0.005875007,\n",
       " -0.0044111675,\n",
       " -0.01804451,\n",
       " 0.0031242815,\n",
       " -0.008112769,\n",
       " 0.0048266225,\n",
       " 0.0058866674,\n",
       " -0.005596388,\n",
       " 0.0011534503,\n",
       " 0.0020037761,\n",
       " 0.0103927655,\n",
       " -0.0064884955,\n",
       " 0.005295532,\n",
       " 0.003183372,\n",
       " 0.010946964,\n",
       " -0.0066405875,\n",
       " -0.011997446,\n",
       " 0.0066000978,\n",
       " -0.0025249457,\n",
       " -0.0015702466,\n",
       " -0.008435319,\n",
       " -0.006273313,\n",
       " -0.004670576,\n",
       " 0.0054938486,\n",
       " 0.002342565,\n",
       " -0.004871191,\n",
       " 0.010292334,\n",
       " -0.0022097847,\n",
       " -0.0009892056,\n",
       " -0.007336214,\n",
       " -0.0045350413,\n",
       " 0.009744111,\n",
       " 0.010404005,\n",
       " -0.0004878793,\n",
       " 0.0014673879,\n",
       " -0.011123077,\n",
       " -0.0034743112,\n",
       " 0.0016828552,\n",
       " -0.010952617,\n",
       " 0.008813763,\n",
       " -0.013720536,\n",
       " -0.013068876,\n",
       " 0.002364356,\n",
       " -0.003396391,\n",
       " 0.008756769,\n",
       " 0.0075539737,\n",
       " 0.00946679,\n",
       " -0.0063212146,\n",
       " -0.0010374103,\n",
       " 0.0056899297,\n",
       " -0.0051962966,\n",
       " 0.0013530306,\n",
       " -0.0018316465,\n",
       " 0.00010911655,\n",
       " 0.0012545357,\n",
       " -0.003658487,\n",
       " -0.0016044964,\n",
       " 0.009139905,\n",
       " 0.0030576517,\n",
       " -0.002446016,\n",
       " -0.0020092956,\n",
       " -0.024376996,\n",
       " -0.0132140145,\n",
       " 0.014699158,\n",
       " 0.011583976,\n",
       " 0.012095452,\n",
       " -0.039833926,\n",
       " -0.048372712,\n",
       " 0.0053127906,\n",
       " -0.0033622417,\n",
       " -0.018179698,\n",
       " -0.016452098,\n",
       " 0.025188752,\n",
       " 0.0042172717,\n",
       " 0.012502486,\n",
       " 0.0067910193,\n",
       " -0.033393264,\n",
       " -0.0049542994,\n",
       " 0.0008985809,\n",
       " -0.022774307,\n",
       " -0.0021298358,\n",
       " 0.0043918914,\n",
       " -0.019737275,\n",
       " 0.0013283693,\n",
       " -0.010335708,\n",
       " 0.020341279,\n",
       " -0.0031945205,\n",
       " -0.031726148,\n",
       " -0.01274511,\n",
       " 0.015649416,\n",
       " -0.008673151,\n",
       " 0.014540044,\n",
       " 0.058449663,\n",
       " -0.011256726,\n",
       " -0.037965577,\n",
       " 0.049095698,\n",
       " -0.024482274,\n",
       " 0.008794316,\n",
       " -0.015451357,\n",
       " -0.009072465,\n",
       " -0.047301114,\n",
       " -0.0063712127,\n",
       " -0.02313915,\n",
       " 0.029668355,\n",
       " -0.014875116,\n",
       " 0.020235723,\n",
       " 0.0035591181,\n",
       " -0.02401188,\n",
       " 0.027701104,\n",
       " -0.009279677,\n",
       " 0.044391435,\n",
       " -0.019178167,\n",
       " 0.029902192,\n",
       " 0.020923901,\n",
       " 0.004696616,\n",
       " 0.017986821,\n",
       " -0.032563165,\n",
       " -0.023827478,\n",
       " -0.0020879041,\n",
       " -0.022072358,\n",
       " -0.031480737,\n",
       " -0.033123296,\n",
       " 0.0070792055,\n",
       " 0.014710962,\n",
       " 0.022578951,\n",
       " -0.010424433,\n",
       " -0.02765896,\n",
       " 0.006256404,\n",
       " 0.013677415,\n",
       " -0.02164862,\n",
       " 0.009488726,\n",
       " -0.0018060216,\n",
       " 0.01740683,\n",
       " -0.021906199,\n",
       " -0.048623852,\n",
       " 0.017044442,\n",
       " 0.010013547,\n",
       " 0.0005956054,\n",
       " -0.010457129,\n",
       " -0.019983096,\n",
       " -0.022545319,\n",
       " 0.055501863,\n",
       " 0.012779812,\n",
       " -0.003923726,\n",
       " -0.020560438,\n",
       " -0.007052071,\n",
       " 0.0022168763,\n",
       " 0.019904481,\n",
       " -0.020189188,\n",
       " 0.012033966,\n",
       " -0.043797124,\n",
       " 0.025802964,\n",
       " 0.012768167,\n",
       " 0.037162136,\n",
       " -0.012393991,\n",
       " -0.03192828,\n",
       " 0.005393332,\n",
       " 0.0041240454,\n",
       " -0.0031319084,\n",
       " -0.026595972,\n",
       " -0.004070573,\n",
       " -0.0065507255,\n",
       " -0.0029021238,\n",
       " -0.017088093,\n",
       " 0.019683365,\n",
       " 0.001034181,\n",
       " 0.0010283006,\n",
       " 0.022096395,\n",
       " -0.005048618,\n",
       " -0.011456652,\n",
       " -0.0024231705,\n",
       " 0.021574434,\n",
       " -0.013466593,\n",
       " 0.034020983,\n",
       " 0.0039875247,\n",
       " -0.0019669794,\n",
       " 0.022375911,\n",
       " -0.0015585907,\n",
       " 0.0035340171,\n",
       " 0.00031717695,\n",
       " 0.0023496773,\n",
       " -0.0033227515,\n",
       " 0.004330507,\n",
       " 0.01071257,\n",
       " 0.029142693,\n",
       " -0.0054998617,\n",
       " 0.013370761,\n",
       " -0.0038640385,\n",
       " 0.00012839533,\n",
       " -0.0019501739,\n",
       " -0.021360124,\n",
       " 0.022749485,\n",
       " 0.029500484,\n",
       " 0.014212664,\n",
       " 0.008275126,\n",
       " 0.019338746,\n",
       " 0.0007437599,\n",
       " 0.01663856,\n",
       " 0.019784877,\n",
       " -0.02310034,\n",
       " 0.029076397,\n",
       " -0.019852456,\n",
       " -0.040222652,\n",
       " 0.01429907,\n",
       " -0.025683392,\n",
       " 0.011339542,\n",
       " 0.022517914,\n",
       " -0.023401858,\n",
       " 0.0077695795,\n",
       " 0.008554706,\n",
       " 0.033079613,\n",
       " -0.018898036,\n",
       " 0.0031258785,\n",
       " 0.0020937852,\n",
       " 0.040320683,\n",
       " -0.007970079,\n",
       " -0.05007362,\n",
       " 0.012052353,\n",
       " -0.0004423523,\n",
       " 0.004716929,\n",
       " -0.03353539,\n",
       " -0.011089971,\n",
       " 0.0018330243,\n",
       " 0.012565319,\n",
       " -0.0023597432,\n",
       " -0.014922862,\n",
       " 0.022634706,\n",
       " 0.008627693,\n",
       " -0.010634747,\n",
       " -0.01947203,\n",
       " -0.0141731715,\n",
       " 0.0107695265,\n",
       " 0.017811919,\n",
       " -0.0073046195,\n",
       " -0.00039050728,\n",
       " -0.026110416,\n",
       " -0.027065808,\n",
       " 0.01646225,\n",
       " -0.025492897,\n",
       " 0.038718354,\n",
       " -0.03690543,\n",
       " -0.019997433,\n",
       " 0.0034906403,\n",
       " -0.0064660856,\n",
       " 0.014468725,\n",
       " 0.027685976,\n",
       " 0.026899852,\n",
       " -0.016930364,\n",
       " -0.026726348,\n",
       " 0.011375512,\n",
       " -0.014821337,\n",
       " 0.0041589555,\n",
       " -0.0027141597,\n",
       " 0.015825527,\n",
       " -0.007497991,\n",
       " -0.008803309,\n",
       " 0.0051733158,\n",
       " 0.019962925,\n",
       " 0.01090171,\n",
       " -0.004085154,\n",
       " 0.0026998664,\n",
       " -0.0327795,\n",
       " -0.022068627,\n",
       " 0.013109931,\n",
       " 0.013280013,\n",
       " 0.018311488,\n",
       " -0.051082827,\n",
       " -0.064461045,\n",
       " 0.007945225,\n",
       " 0.0012713739,\n",
       " -0.02619678,\n",
       " -0.03897003,\n",
       " 0.038848784,\n",
       " 0.016136458,\n",
       " 0.023400912,\n",
       " 0.02056677,\n",
       " -0.047511466,\n",
       " -0.013447735,\n",
       " -0.001607895,\n",
       " -0.030981222,\n",
       " -0.00026184137,\n",
       " 0.05158049,\n",
       " -0.034289062,\n",
       " 0.0017709984,\n",
       " -0.015151355,\n",
       " 0.03131364,\n",
       " -0.010967025,\n",
       " -0.055662304,\n",
       " -0.02917253,\n",
       " 0.026597593,\n",
       " -0.010853788,\n",
       " 0.04323471,\n",
       " 0.102605864,\n",
       " -0.020932624,\n",
       " -0.053893153,\n",
       " 0.03850707,\n",
       " -0.04563407,\n",
       " 0.015264393,\n",
       " -0.026928645,\n",
       " -0.010055288,\n",
       " -0.09255701,\n",
       " -0.023687972,\n",
       " -0.036763452,\n",
       " 0.054630376,\n",
       " -0.018564545,\n",
       " 0.025234303,\n",
       " 0.0064799315,\n",
       " -0.037061177,\n",
       " 0.055138465,\n",
       " -0.016752515,\n",
       " 0.07063069,\n",
       " -0.033642683,\n",
       " 0.0467521,\n",
       " 0.027380737,\n",
       " 0.011003628,\n",
       " 0.046762038,\n",
       " -0.018656526,\n",
       " -0.051177073,\n",
       " -0.0069092624,\n",
       " -0.03631489,\n",
       " -0.055516917,\n",
       " -0.062376015,\n",
       " 0.0029821997,\n",
       " 0.024521142,\n",
       " 0.03801189,\n",
       " -0.008277937,\n",
       " -0.042800963,\n",
       " 0.013210997,\n",
       " 0.022339426,\n",
       " -0.035021544,\n",
       " 0.019614097,\n",
       " -0.02064391,\n",
       " 0.03667903,\n",
       " -0.035037223,\n",
       " -0.0902297,\n",
       " 0.035034463,\n",
       " 0.010665247,\n",
       " 0.0011008461,\n",
       " -0.0075910976,\n",
       " -0.03165782,\n",
       " -0.03645885,\n",
       " 0.09430214,\n",
       " 0.027124103,\n",
       " -0.00798479,\n",
       " -0.033437755,\n",
       " -0.014873546,\n",
       " 0.012711045,\n",
       " 0.031325456,\n",
       " -0.041885,\n",
       " 0.016968727,\n",
       " -0.08427937,\n",
       " 0.045068003,\n",
       " 0.016834669,\n",
       " 0.053795446,\n",
       " -0.021546941,\n",
       " -0.05074768,\n",
       " 0.018895688,\n",
       " 0.0068552103,\n",
       " -0.017058099,\n",
       " -0.051816102,\n",
       " -0.015008796,\n",
       " -0.011859429,\n",
       " -0.0064024143,\n",
       " -0.044074386,\n",
       " 0.04929404,\n",
       " 0.005217501,\n",
       " 0.0108496,\n",
       " 0.026881455,\n",
       " -0.007785702,\n",
       " -0.028859064,\n",
       " -0.0011010013,\n",
       " 0.045188185,\n",
       " -0.014537774,\n",
       " 0.056880675,\n",
       " 0.009735458,\n",
       " 0.004117318,\n",
       " 0.035075776,\n",
       " 0.004625513,\n",
       " 0.037707426,\n",
       " -0.0038716085,\n",
       " -0.011731612,\n",
       " -0.01572846,\n",
       " 0.010271379,\n",
       " 0.01443629,\n",
       " 0.04908988,\n",
       " -0.008825154,\n",
       " 0.028118571,\n",
       " 0.00011863902,\n",
       " 0.0051353113,\n",
       " -0.020089976,\n",
       " -0.0273425,\n",
       " 0.045677368,\n",
       " 0.045879107,\n",
       " 0.022753943,\n",
       " 0.023849512,\n",
       " 0.032254476,\n",
       " 0.0113756955,\n",
       " 0.021449383,\n",
       " 0.040979598,\n",
       " -0.03412869,\n",
       " 0.052665427,\n",
       " -0.030667914,\n",
       " -0.07135246,\n",
       " 0.027079178,\n",
       " -0.03693539,\n",
       " 0.031744376,\n",
       " 0.045679912,\n",
       " -0.040966645,\n",
       " 0.015102807,\n",
       " 0.02096668,\n",
       " 0.06624486,\n",
       " -0.030774087,\n",
       " 0.0036689087,\n",
       " -0.0002813199,\n",
       " 0.06728078,\n",
       " -0.013288417,\n",
       " -0.08480898,\n",
       " 0.019065317,\n",
       " 0.0071226778,\n",
       " 0.0069624907,\n",
       " -0.061754417,\n",
       " -0.020887578,\n",
       " -0.0043466245,\n",
       " 0.0142998425,\n",
       " 0.005929689,\n",
       " -0.022649629,\n",
       " 0.043354258,\n",
       " 0.00864945,\n",
       " -0.020715423,\n",
       " -0.034738287,\n",
       " -0.035635732,\n",
       " 0.02907881,\n",
       " 0.03677322,\n",
       " -0.007878418,\n",
       " -0.0062702694,\n",
       " -0.034833122,\n",
       " -0.043463938,\n",
       " 0.028642874,\n",
       " -0.050034598,\n",
       " 0.0608231,\n",
       " -0.06168098,\n",
       " -0.039304733,\n",
       " 0.0011453596,\n",
       " -0.0016296583,\n",
       " 0.03403347,\n",
       " 0.033899628,\n",
       " 0.03626052,\n",
       " -0.026155869,\n",
       " -0.02552882,\n",
       " 0.012041803,\n",
       " -0.023833832,\n",
       " 0.0031137161,\n",
       " -0.01064474,\n",
       " 0.022209635,\n",
       " -0.007905669,\n",
       " -0.019103749,\n",
       " 0.017686388,\n",
       " 0.03737134,\n",
       " 0.005006827,\n",
       " -0.008617054,\n",
       " -0.005827322,\n",
       " -0.022522705,\n",
       " -0.014112126,\n",
       " 0.0046628946,\n",
       " 0.011088643,\n",
       " 0.011661363,\n",
       " -0.02823367,\n",
       " -0.04157757,\n",
       " 0.008369082,\n",
       " -0.00415549,\n",
       " -0.022710012,\n",
       " -0.017794961,\n",
       " 0.022991603,\n",
       " 0.005527571,\n",
       " 0.008698056,\n",
       " 0.008070699,\n",
       " -0.02495178,\n",
       " -0.0038959754,\n",
       " 0.00074571586,\n",
       " -0.013467557,\n",
       " -0.0003668637,\n",
       " 0.04112789,\n",
       " -0.012385297,\n",
       " -0.0037758814,\n",
       " -0.0038595549,\n",
       " 0.010940017,\n",
       " -0.005267016,\n",
       " -0.029310977,\n",
       " -0.012530958,\n",
       " 0.015419054,\n",
       " -0.00026994187,\n",
       " 0.018278798,\n",
       " 0.054007024,\n",
       " -0.01424305,\n",
       " -0.029999638,\n",
       " 0.014719864,\n",
       " -0.020714432,\n",
       " 0.009353121,\n",
       " -0.0100129815,\n",
       " -0.0022669772,\n",
       " -0.05020373,\n",
       " -0.011161181,\n",
       " -0.023228768,\n",
       " 0.029073423,\n",
       " -0.006983311,\n",
       " 0.012702873,\n",
       " -0.0017111662,\n",
       " -0.017455257,\n",
       " 0.031441316,\n",
       " -0.009084023,\n",
       " 0.03872049,\n",
       " -0.019126724,\n",
       " 0.02308656,\n",
       " 0.013282121,\n",
       " 0.007858824,\n",
       " 0.023042357,\n",
       " -0.011386025,\n",
       " -0.025842015,\n",
       " -0.0008985444,\n",
       " -0.017175185,\n",
       " -0.02576377,\n",
       " -0.030359669,\n",
       " 0.0024265037,\n",
       " 0.01288104,\n",
       " 0.017774386,\n",
       " -0.010392964,\n",
       " -0.022823522,\n",
       " 0.0028251167,\n",
       " 0.016675511,\n",
       " -0.02403164,\n",
       " 0.009392655,\n",
       " -0.0068628527,\n",
       " 0.015918711,\n",
       " -0.020872047,\n",
       " -0.04992739,\n",
       " 0.019487582,\n",
       " 0.008554871,\n",
       " 0.0038533316,\n",
       " -0.008614339,\n",
       " -0.015627982,\n",
       " -0.016516048,\n",
       " 0.05530492,\n",
       " 0.008492302,\n",
       " -0.00390697,\n",
       " -0.023203533,\n",
       " -0.0068835323,\n",
       " 0.005844039,\n",
       " 0.012508217,\n",
       " -0.02491227,\n",
       " 0.008279227,\n",
       " -0.039876964,\n",
       " 0.025349678,\n",
       " 0.01138734,\n",
       " 0.033818185,\n",
       " -0.0062436424,\n",
       " -0.024434187,\n",
       " 0.004323563,\n",
       " 0.0063338564,\n",
       " -0.007224234,\n",
       " -0.028053498,\n",
       " -0.004832049,\n",
       " -0.0050765774,\n",
       " -0.0030899318,\n",
       " -0.014274972,\n",
       " 0.02433044,\n",
       " 0.0020805604,\n",
       " 0.002954011,\n",
       " 0.01752609,\n",
       " -0.007725443,\n",
       " -0.007826409,\n",
       " -0.00095861964,\n",
       " 0.02117299,\n",
       " -0.013143813,\n",
       " 0.025985438,\n",
       " 0.010535297,\n",
       " 0.0021380577,\n",
       " 0.016189707,\n",
       " 0.0010583281,\n",
       " 0.03135292,\n",
       " -0.0061841737,\n",
       " -0.012950608,\n",
       " -0.020453561,\n",
       " 0.008550219,\n",
       " 0.017903237,\n",
       " 0.026437998,\n",
       " -0.0132018365,\n",
       " 0.017264951,\n",
       " -0.0053043924,\n",
       " 0.0051580877,\n",
       " -0.022757662,\n",
       " -0.011560365,\n",
       " 0.020232687,\n",
       " 0.024102258,\n",
       " 0.009367823,\n",
       " 0.006010249,\n",
       " 0.014571642,\n",
       " 0.00058022887,\n",
       " 0.010527918,\n",
       " 0.022108052,\n",
       " -0.01535675,\n",
       " 0.027462024,\n",
       " -0.020147253,\n",
       " -0.03934983,\n",
       " 0.0070318347,\n",
       " -0.02368339,\n",
       " 0.012583419,\n",
       " 0.019126572,\n",
       " -0.02815035,\n",
       " 0.009591236,\n",
       " 0.011701873,\n",
       " 0.031442057,\n",
       " -0.021878634,\n",
       " 0.004126426,\n",
       " 0.0030310494,\n",
       " 0.033603996,\n",
       " -0.009209451,\n",
       " -0.046235077,\n",
       " 0.0069808187,\n",
       " 0.007840409,\n",
       " 0.0048167505,\n",
       " -0.029939368,\n",
       " -0.01190869,\n",
       " -0.0041826623,\n",
       " 0.011487984,\n",
       " 0.0042777155,\n",
       " -0.0068165655,\n",
       " 0.021446895,\n",
       " 0.0015272897,\n",
       " -0.0117651615,\n",
       " -0.014732021,\n",
       " -0.014272126,\n",
       " 0.013295284,\n",
       " 0.018593496,\n",
       " -0.0020486994,\n",
       " -0.00209361,\n",
       " -0.020183984,\n",
       " -0.01812864,\n",
       " 0.016861107,\n",
       " -0.02824949,\n",
       " 0.036814824,\n",
       " -0.037953638,\n",
       " -0.020089991,\n",
       " -0.004266458,\n",
       " -0.0017040558,\n",
       " 0.02105513,\n",
       " 0.020647211,\n",
       " 0.016984014,\n",
       " -0.01647395,\n",
       " -0.018471656,\n",
       " 0.0031959368,\n",
       " -0.013481996,\n",
       " -0.0014185826,\n",
       " -0.0054194815,\n",
       " 0.011044826,\n",
       " -0.004360446,\n",
       " -0.01197136,\n",
       " 0.011102953,\n",
       " 0.016636658,\n",
       " -0.002415689,\n",
       " 0.004880977,\n",
       " 0.0017166998,\n",
       " 0.04670587,\n",
       " 0.028576912,\n",
       " -0.028456954,\n",
       " -0.023243155,\n",
       " -0.038227785,\n",
       " 0.08171205,\n",
       " 0.119553454,\n",
       " -0.019088931,\n",
       " 0.0010000707,\n",
       " 0.060754847,\n",
       " 0.030147051,\n",
       " -0.040761806,\n",
       " -0.011815359,\n",
       " -0.024390223,\n",
       " -0.022023357,\n",
       " 0.038967375,\n",
       " 0.01199133,\n",
       " 0.008484336,\n",
       " 0.027269075,\n",
       " 0.0006218154,\n",
       " -0.11002847,\n",
       " 0.03350974,\n",
       " 0.00279451,\n",
       " 0.0104325,\n",
       " -0.034688167,\n",
       " 0.007558195,\n",
       " 0.05904265,\n",
       " 0.027217962,\n",
       " -0.031129053,\n",
       " 0.007866469,\n",
       " -0.027251646,\n",
       " -0.10896583,\n",
       " 0.019622952,\n",
       " 0.055953022,\n",
       " -0.03288511,\n",
       " 0.051904794,\n",
       " -0.012984409,\n",
       " 0.0236889,\n",
       " 0.0149592515,\n",
       " 0.099771015,\n",
       " 0.023258086,\n",
       " 0.04543366,\n",
       " -0.055971187,\n",
       " 0.027942196,\n",
       " -0.029953051,\n",
       " -0.0027587072,\n",
       " 0.04323849,\n",
       " -0.058033846,\n",
       " 0.022206899,\n",
       " -0.07796215,\n",
       " 0.03251434,\n",
       " -0.0676017,\n",
       " -0.027389375,\n",
       " -0.010496012,\n",
       " -0.045474038,\n",
       " 0.024392366,\n",
       " 0.055113215,\n",
       " 0.011910288,\n",
       " 0.04462217,\n",
       " 0.058628205,\n",
       " 0.06850869,\n",
       " -0.010644435,\n",
       " -0.02298683,\n",
       " -0.04844483,\n",
       " 0.010844402,\n",
       " 0.047170825,\n",
       " -0.011655912,\n",
       " -0.024331816,\n",
       " 0.044110857,\n",
       " -0.020711733,\n",
       " 0.013315621,\n",
       " -0.03931846,\n",
       " 0.041518785,\n",
       " 0.098895214,\n",
       " -0.042350687,\n",
       " -0.013666251,\n",
       " -0.0052957023,\n",
       " 0.015936349,\n",
       " 0.03713234,\n",
       " 0.036857363,\n",
       " -0.11023231,\n",
       " -0.02812827,\n",
       " 0.0027163525,\n",
       " 0.038132805,\n",
       " 0.02208219,\n",
       " -0.0059640077,\n",
       " -0.037401978,\n",
       " 0.041055463,\n",
       " -0.021587102,\n",
       " 0.09019063,\n",
       " -0.05179937,\n",
       " -0.020737218,\n",
       " -0.06267626,\n",
       " 0.019954486,\n",
       " 0.055833485,\n",
       " -0.012868937,\n",
       " -0.006956223,\n",
       " 0.011353513,\n",
       " 0.055944752,\n",
       " 0.009326364,\n",
       " 0.009317761,\n",
       " 0.012250408,\n",
       " 0.031622067,\n",
       " -0.055934228,\n",
       " -0.0027837292,\n",
       " -0.0018072628,\n",
       " -0.010018213,\n",
       " 0.008537347,\n",
       " 0.028983109,\n",
       " -0.00041311618,\n",
       " -0.043131925,\n",
       " 0.021605123,\n",
       " -0.06694032,\n",
       " -0.014510292,\n",
       " -0.0067992425,\n",
       " -0.036186807,\n",
       " -0.00035792106,\n",
       " -0.09869972,\n",
       " 0.011977023,\n",
       " 0.02916763,\n",
       " 0.05124216,\n",
       " -0.036833104,\n",
       " -0.0431461,\n",
       " -0.055997595,\n",
       " 0.032212935,\n",
       " -0.040095117,\n",
       " 7.0649407e-06,\n",
       " -0.005134432,\n",
       " 0.062079806,\n",
       " 0.034451425,\n",
       " -0.041012038,\n",
       " -0.05501978,\n",
       " -0.019381901,\n",
       " -0.019920412,\n",
       " -0.04010957,\n",
       " -0.008853332,\n",
       " -0.01996385,\n",
       " -0.03566486,\n",
       " 0.040447623,\n",
       " -0.056962818,\n",
       " 0.033314653,\n",
       " 0.07378433,\n",
       " -0.022106444,\n",
       " 0.047422376,\n",
       " -0.035063326,\n",
       " -0.045387805,\n",
       " 0.0555875,\n",
       " -0.024168657,\n",
       " -0.02400187,\n",
       " -0.0666578,\n",
       " 0.035232794,\n",
       " -0.0031649028,\n",
       " -0.0007707802,\n",
       " -0.0743182,\n",
       " 0.015161451,\n",
       " 0.09727696,\n",
       " -0.023689998,\n",
       " -0.011279413,\n",
       " -0.011054308,\n",
       " 0.07285067,\n",
       " 0.016417647,\n",
       " -0.0013262494,\n",
       " -0.017893799,\n",
       " -0.004356321,\n",
       " 0.021107804,\n",
       " -0.060429957,\n",
       " -0.014510273,\n",
       " 0.027386896,\n",
       " 0.04454023,\n",
       " 0.03641471,\n",
       " -0.03263836,\n",
       " -0.038613886,\n",
       " 0.019222192,\n",
       " 0.006697854,\n",
       " 0.0455453,\n",
       " 0.04642253,\n",
       " -0.036423568,\n",
       " 0.05348383,\n",
       " -0.07043491,\n",
       " 0.074796975,\n",
       " 0.050074432,\n",
       " 0.0029504152,\n",
       " 0.0061388267,\n",
       " -0.03600563,\n",
       " -0.030897183,\n",
       " -0.03819023,\n",
       " 0.0242026,\n",
       " 0.032004163,\n",
       " -0.01748994,\n",
       " 0.022717899,\n",
       " -0.004577944,\n",
       " 0.004273998,\n",
       " -0.029115224,\n",
       " 0.008767551,\n",
       " 0.017649593,\n",
       " -0.01645721,\n",
       " -0.041114416,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordtoken_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised fastText pos training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('hsd/DavidsonEtAl/fasttext_pos.ft'):\n",
    "    with open('hsd/DavidsonEtAl/fasttext_pos.ft', 'a') as f:\n",
    "        for t, l in list(zip(tweets, labels)):\n",
    "            f.write('__label__{} {}\\n'.format(l, get_pos_string(t)))\n",
    "\n",
    "# load fasttext pos model or train & save if none\n",
    "if os.path.exists('hsd/DavidsonEtAl/fasttext_pos_{}.bin'.format(MODEL)):\n",
    "    ft_pos_model = fasttext.load_model('hsd/DavidsonEtAl/fasttext_pos_{}.bin'.format(MODEL))\n",
    "else:\n",
    "    ft_pos_model = fasttext.train_supervised('hsd/DavidsonEtAl/fasttext_pos.ft',\n",
    "                                             lr=0.5, epoch=50, wordNgrams=3, dim=dim)\n",
    "    ft_pos_model.save_model('hsd/DavidsonEtAl/fasttext_pos_{}.bin'.format(MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech (PoS) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_fts(data, length=None):\n",
    "\n",
    "    #Get POS tags for tweets and save as a string\n",
    "    pos_sentences = []\n",
    "    t = tqdm(data)\n",
    "    t.set_postfix_str('PoS features extraction: tokenization.')\n",
    "    for d in t:\n",
    "        pos_string = get_pos_string(d)\n",
    "        pos_sentences.append(pos_string)\n",
    "        \n",
    "        \n",
    "    pos_tags = []\n",
    "    for ps in pos_sentences:\n",
    "        pos_tags.append(ps.split(' '))\n",
    "    \n",
    "    if length:\n",
    "        pos_tags = [adjust_words(pt, length) for pt in pos_tags]\n",
    "        print('Required length: {}'.format(length))\n",
    "    else:\n",
    "        opt_length = int(np.median([len(pt) for pt in pos_tags]))\n",
    "        print('Optimal median length: {}'.format(opt_length))\n",
    "        pos_tags = [pad_words(pt, opt_length) for pt in pos_tags]\n",
    "    \n",
    "    ft_vectors = []\n",
    "    t = tqdm(pos_tags)\n",
    "    t.set_postfix_str('PoS features extraction: vectorization.')\n",
    "    for pt in t:\n",
    "        ft_vector = []\n",
    "        for t in pt:\n",
    "            ft_vector.extend(ft_pos_model[t])\n",
    "        ft_vectors.append(ft_vector)\n",
    "    \n",
    "    return ft_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11011c470fb4f26bbd53be74c0a3a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24783), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal median length: 49\n"
     ]
    }
   ],
   "source": [
    "pos_features = get_pos_fts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_fts(data):\n",
    "    other_features = []\n",
    "    t = tqdm(data)\n",
    "    t.set_postfix_str('Other features extraction.')\n",
    "    for tweet in t:\n",
    "        \"\"\"This function takes a string and returns a list of features.\n",
    "        These include Sentiment scores, Text and Readability scores,\n",
    "        as well as Twitter specific features\"\"\"\n",
    "        sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
    "\n",
    "        words = preprocess(tweet) #Get text only\n",
    "\n",
    "        syllables = sylla.estimate(words)\n",
    "        num_chars = sum(len(w) for w in words)\n",
    "        num_chars_total = len(tweet)\n",
    "        num_terms = len(tweet.split())\n",
    "        num_words = len(words.split())\n",
    "        avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "        num_unique_terms = len(set(words.split()))\n",
    "\n",
    "        ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "        FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59, 1)\n",
    "        ##Modified FRE score, where sentence fixed to 1\n",
    "        FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)), 2)\n",
    "\n",
    "        twitter_objs = count_twitter_objs(tweet)\n",
    "        retweet = 0 if \"rt\" in words else 1\n",
    "        features = [FKRA, FRE, syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                    num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                    twitter_objs[2], twitter_objs[1],\n",
    "                    twitter_objs[0], retweet]\n",
    "        other_features.append(features)\n",
    "    \n",
    "    return np.array(other_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = get_other_fts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features and feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "features = np.concatenate([wordtoken_features, pos_features, other_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = dir_archive('hsd/DavidsonEtAl/X_y_{}'.format(MODEL), {'features': features, 'labels': labels}, serialized=True)\n",
    "archive.dump()\n",
    "del archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Detector - EN - Features extraction for EN test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCHES = 50\n",
    "\n",
    "TOKENS_LENGTH = 13\n",
    "POS_LENGTH = 12\n",
    "\n",
    "if os.path.exists('tests/tweets_en.csv'):\n",
    "    with open('tests/tweets_en.csv', 'r') as f:\n",
    "        raw_tweets = [d[0] for d in tqdm(list(csv.reader(f))[1:])]\n",
    "    \n",
    "    q, r = divmod(len(raw_tweets), BATCHES)\n",
    "    tweets_batches = [raw_tweets[i * q + min(i, r):(i + 1) * q + min(i + 1, r)] for i in xrange(BATCHES)]\n",
    "    \n",
    "    for batch in range(BATCHES):\n",
    "        print('Batch {}/{}'.format(batch+1, BATCHES))\n",
    "        tweets_batch = tweets_batches[batch]\n",
    "    \n",
    "        wt_features = get_wordtoken_fts(tweets_batch, length=TOKENS_LENGTH)\n",
    "        p_features = get_pos_fts(tweets_batch, length=POS_LENGTH)\n",
    "        o_features = get_other_fts(tweets_batch)\n",
    "\n",
    "        all_features = np.concatenate([wt_features, p_features, o_features], axis=1)\n",
    "        print('Done! Extracted dimensions: {}'.format(all_features.shape))\n",
    "        \n",
    "        batch_str = str(batch) if batch >= 100 else '0'+str(batch) if batch >= 10 else '00'+str(batch)\n",
    "        archive = dir_archive('tests/en_{}/X_{}'.format(MODEL, batch_str), {'features': all_features}, serialized=True)\n",
    "        archive.dump()\n",
    "        del archive\n",
    "    print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
